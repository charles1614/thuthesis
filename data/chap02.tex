% !TeX root = ../thuthesis-example.tex

\chapter{相关工作}

本章系统性地回顾与本论文研究方向密切相关的理论基础和技术发展脉络。我们将从三个维度展开深入分析：首先回顾神经场景表示方法的理论演进历程，重点分析其在大规模动态场景建模中面临的技术挑战和现有解决方案；其次综述扩散模型在三维内容生成领域的理论突破和应用进展，深入探讨其为三维场景重建带来的新机遇；最后全面分析神经表示与生成模型融合的前沿方法，识别现有技术的系统性局限并明确本论文的技术定位和创新空间。

\section{神经场景表示的理论演进与技术突破}

神经场景表示技术的发展历程可以追溯到隐式神经表示理论的奠基性工作。这一理论体系的核心思想是利用神经网络学习连续函数，将空间坐标直接映射到场景的各种属性。Neural Radiance Fields（NeRF）的提出标志着隐式神经表示在场景重建领域的重大突破\cite{mildenhall2021nerf}。NeRF将三维场景建模为一个连续的五维函数，该函数能够将三维空间位置和二维观测方向映射为体积密度和辐射颜色。这种表示方法的理论优势在于其天然的连续性和可微性，使得模型能够通过标准的梯度下降方法直接从二维图像监督中学习复杂的三维场景结构，无需依赖额外的几何先验知识或显式的三维监督信号。

NeRF的成功激发了学术界对隐式神经表示的广泛关注，但其在处理大规模场景时的局限性也逐渐显现。为了解决这一问题，研究者们提出了多种分治策略。Block-NeRF采用空间分割的方法，将大规模场景分解为多个重叠的子区域，每个子区域使用独立的NeRF模型进行建模\cite{blocknerf2022}。这种方法的优势在于能够并行处理不同的空间区域，显著提升了训练效率和推理速度。Mega-NeRF进一步扩展了这一思想，提出了基于八叉树的层次化分割策略，能够有效处理城市级别的大规模场景\cite{meganeRF2022}。然而，这些分治方法也引入了新的技术挑战，包括子模型间的边界处理、全局一致性的保证以及模型管理的复杂性等问题。

将NeRF扩展到动态场景建模是另一个重要的研究方向，但也面临着理论上的根本性挑战。给定一组二维观测图像，可能存在多种在数学上等价但物理上截然不同的动态过程，这使得动态场景重建成为一个高度不适定的问题。D-NeRF通过在NeRF的输入中引入时间维度来解决这一问题，将静态的三维函数扩展为四维的时空函数\cite{dnerf2021}。Nerfies采用了不同的技术路线，通过学习从观测空间到规范空间的形变场来处理动态场景\cite{nerfies2021}。这种方法的核心思想是将所有时刻的观测都映射到一个统一的规范空间中，然后在规范空间中应用标准的NeRF技术。

K-Planes提出了一种更加高效的动态场景表示方法，通过多个二维平面的外积来表示四维的时空场\cite{kplanes2023}。这种分解方法的优势在于显著降低了模型的参数数量和计算复杂度，同时保持了对复杂时空变化的建模能力。EmerNeRF则实现了完全自监督的动静分离，通过同时学习静态场和动态场，并引入密度正则化项来鼓励稀疏的动态表示\cite{emernerf2023}。这种方法的创新之处在于无需额外的语义标注或运动估计，能够自动将场景分解为静态背景和动态前景。

尽管隐式表示方法在质量上取得了显著进展，但其计算效率的问题始终没有得到根本性解决。3D Gaussian Splatting（3DGS）的出现标志着神经场景表示技术从隐式到显式的重要范式转变\cite{kerbl2023gaussian}。3DGS将场景表示为三维高斯基元的集合，每个高斯基元通过位置、协方差矩阵、不透明度和颜色等参数进行完整描述。这种显式表示方法的最大优势在于渲染效率的革命性提升，通过可微分的点splatting技术，3DGS能够实现超过100帧每秒的实时渲染性能，为实际应用部署奠定了坚实基础。

3DGS的成功也推动了显式表示方法在动态场景中的应用探索。Street Gaussians将3DGS扩展到动态驾驶场景，采用动静分离的策略来处理复杂的城市交通环境\cite{yan2024street}。该方法将场景分解为静态的背景高斯和动态的物体高斯，通过刚体变换来描述动态物体的运动。这种分解策略的优势在于能够有效利用场景的结构化特性，显著提升建模效率和渲染质量。

然而，显式表示方法也带来了新的技术挑战，特别是在视点外推能力方面的显著退化。与隐式表示的连续函数不同，显式表示的离散基元在训练数据覆盖不足的空间区域缺乏有效的插值机制。当查询视点偏离训练分布时，容易出现几何不一致和明显的视觉伪影，这严重限制了其在需要广泛视点覆盖的应用场景中的实用价值。

\section{扩散模型在三维生成中的理论突破}

扩散模型的理论基础建立在随机微分方程和分数匹配理论之上，为生成建模提供了全新的理论框架。去噪扩散概率模型（DDPM）通过定义前向扩散过程和反向去噪过程，实现了对复杂数据分布的有效建模\cite{ho2020denoising}。前向扩散过程逐步向原始数据中添加高斯噪声，直到数据完全被噪声掩盖；反向去噪过程则通过神经网络学习逆向操作，从纯噪声中逐步恢复原始数据。这种设计的理论优势在于将复杂的生成问题分解为一系列相对简单的去噪任务，使得模型能够学习到数据分布的精细结构。

扩散模型在二维图像生成领域取得巨大成功后，研究者们开始探索将其扩展到三维内容生成的可能性。这一扩展面临的主要挑战是如何有效利用二维扩散模型学习到的先验知识来指导三维内容的生成。DreamFusion提出的分数蒸馏采样（SDS）为解决这一问题提供了重要的理论框架\cite{dreamfusion2022}。SDS的核心思想是将预训练的二维扩散模型转化为可微分的损失函数，通过梯度反传的方式指导三维表示的优化过程。这种方法的理论创新在于建立了二维监督信号与三维表示参数之间的直接联系，使得三维生成能够受益于二维扩散模型的强大先验知识。

SDS方法的成功激发了后续一系列改进工作的出现。ProlificDreamer提出了变分分数蒸馏（VSD），将三维参数视为概率分布而非确定性点估计，通过粒子优化方法提升生成质量和多样性\cite{prolificdreamer2023}。VSD的理论贡献在于引入了低保真度的参考模型，通过对比学习的方式减少了梯度估计的方差，提升了优化过程的稳定性。LucidDreamer通过区间分数匹配（ISM）进一步改进了SDS，提供了更加稳定和高效的梯度估计方法\cite{luciddreamer2023}。ISM的核心思想是在特定的时间区间内进行分数匹配，避免了传统方法在极端噪声水平下的不稳定性问题。

除了基于SDS的间接生成方法，研究者们也探索了直接在三维空间中应用扩散模型的可能性。DreamGaussian将SDS框架应用于3DGS，实现了从单张图像到三维高斯表示的快速生成\cite{dreamgaussian2023}。该方法的技术创新在于设计了渐进式的密化和剪枝策略，能够在优化过程中动态调整高斯基元的数量和分布，实现了生成质量和计算效率的良好平衡。

潜在空间扩散是另一个重要的技术方向，通过在压缩的潜在空间中进行扩散建模来提升计算效率。GAUDI和L3DG采用了这种策略，首先学习三维场景的压缩表示，然后在潜在空间中进行扩散建模\cite{gaudi2022,rossle2024l3dg}。这种方法的优势在于能够显著降低扩散模型的计算复杂度，同时保持对复杂三维结构的建模能力。然而，潜在空间方法也面临着表示能力和重建质量之间的权衡问题，需要在压缩比和生成质量之间找到合适的平衡点。

尽管扩散模型在三维生成领域取得了显著进展，但其在处理大规模动态场景时仍然面临诸多挑战。首先是计算效率问题，扩散采样过程需要多次迭代，计算成本相对较高。其次是条件控制的精确性，如何精确控制生成内容的几何结构、材质属性和动态行为仍然是一个开放的研究问题。最后是生成一致性的保证，如何确保生成的三维内容在不同视点和时刻保持几何和视觉的一致性也需要进一步的理论和技术突破。

\section{神经表示与生成模型的融合范式}

当前融合神经场景表示与生成模型的研究可以从多个维度进行系统性分析。从融合时机的角度来看，现有方法主要分为三类：预处理融合、训练时融合和后处理融合。预处理融合方法在训练开始前使用生成模型增强训练数据，其优势在于实现简单，不会增加训练过程的复杂性，但缺点是生成数据与真实数据之间可能存在领域差异。训练时融合方法在训练过程中实时调用生成模型，能够实现更加紧密的知识迁移，但也显著增加了训练的计算复杂度。后处理融合方法在训练完成后使用生成模型改善结果，其优势在于不影响原有训练流程，但知识迁移的效果相对有限。

从知识迁移方式的角度来看，现有方法主要采用三种策略：数据增强、损失引导和特征蒸馏。数据增强方法通过生成额外的训练样本来改善模型性能，其理论基础是增加训练数据的多样性能够提升模型的泛化能力。损失引导方法将生成模型提供的损失信号作为额外的监督信息，通过多任务学习的方式实现知识迁移。特征蒸馏方法在特征空间进行知识迁移，通过最小化教师网络和学生网络特征表示之间的差异来实现知识传递。

DriveDreamer4D代表了数据机器范式的典型实现，该方法利用世界模型生成额外的训练数据来改善4DGS模型的性能\cite{drivedreamer4d2024}。其核心思想是通过增加训练数据的视点覆盖范围来缓解视点外推问题。该方法的优势在于实现相对简单，不需要修改原有的训练流程，但也存在明显的局限性。首先是生成数据质量问题，世界模型生成的合成数据与真实数据之间存在分布差异，可能导致模型学习到错误的先验知识。其次是知识迁移效率问题，通过数据增强实现的知识迁移是间接的，无法保证扩散模型的先验知识能够有效传递到三维表示中。

ReconDreamer提出了在线修复范式的创新实现，将生成模型作为实时修复器嵌入训练循环\cite{recondreamer2024}。该方法在每个训练迭代中首先使用当前的三维表示渲染新视点图像，然后使用预训练的修复模型对渲染结果进行改善，最后使用改善后的图像作为监督信号来更新三维表示。这种方法的优势在于能够实现更加直接的知识迁移，修复模型能够实时纠正三维表示的不足之处。然而，这种方法也面临训练复杂度高的问题，需要在每个训练步骤中调用生成模型，显著增加了计算成本。此外，该方法还存在误差累积的风险，修复模型的错误可能会在训练过程中逐渐放大。

StreetCrafter实现了知识蒸馏范式的经典应用，采用两阶段的训练策略来实现扩散先验到4DGS的知识迁移\cite{yan2025streetcrafter}。第一阶段专门训练扩散模型，使其能够根据多模态条件生成高质量的驾驶场景图像。第二阶段则使用训练好的扩散模型来指导4DGS的优化，通过分数蒸馏采样的方式实现知识迁移。这种方法的优势在于知识迁移的直接性和有效性，预训练的扩散模型能够提供高质量的监督信号来指导三维表示的学习。然而，该方法也存在一些技术局限。首先是两阶段流程的低效性，严格的序贯训练流程导致总体训练时间较长，缺乏端到端的优化机制。其次是条件依赖的局限性，该方法对特定类型的条件信息（如LiDAR数据）具有强依赖性，限制了方法的普适性和灵活性。

通过对现有融合方法的深入分析，我们可以识别出几个共同的技术挑战。首先是理论框架的不完善，缺乏统一的理论体系来分析不同融合范式的优劣和适用场景。其次是算法设计的局限性，现有的引导机制相对简单，无法充分利用多模态信息；采样策略缺乏自适应性，难以根据训练状态进行动态调整。最后是系统实现的复杂性，缺乏端到端的优化框架使得组件间的协同效应未能得到充分发挥，内存和计算效率也有待进一步提升。

这些技术挑战为本论文的研究提供了明确的改进方向和创新空间。通过设计更加高效的知识蒸馏框架，开发自适应的采样调度算法，构建多模态的正则化机制，我们有望在保持现有方法优势的基础上，显著提升融合效果和系统性能，为高保真场景重建技术在自动驾驶应用中的实际部署提供更加可靠的技术支撑。

\section{本章小结与技术定位}

本章通过系统性的文献回顾和技术分析，全面梳理了神经场景表示、扩散模型和两者融合的研究现状。神经场景表示技术从NeRF到3DGS的演进体现了从质量到效率、从隐式到显式的技术权衡过程。扩散模型在三维生成中的应用展现了强大的生成先验能力，但如何有效地将这些先验迁移到三维表示中仍然是一个具有挑战性的开放问题。

现有的融合方法各有特色和优势，但都存在不同程度的系统性局限。数据机器范式实现简单但知识迁移效率有限，在线修复范式迁移直接但计算复杂度较高，知识蒸馏范式效果显著但缺乏端到端优化。这些局限性为本论文的技术创新提供了明确的改进空间和研究方向。

基于这一分析，本论文的技术定位可以概括为：在知识蒸馏范式的基础上，通过训练自由引导、自适应采样调度和多模态正则化等技术创新，构建更加高效、稳定和通用的融合框架。这一技术定位不仅具有重要的理论意义，更有望在实际应用中产生显著的性能提升，为高保真场景重建技术在自动驾驶仿真中的广泛应用奠定坚实的技术基础。
